{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.1 64-bit",
   "display_name": "Python 3.8.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "004de6046f1b3d314f33fdb43a2dc798b2646e5600efd8df5066c8b63a00ff6d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Advanced Network Management - Assignment 1\n",
    "\n",
    "## Tasks\n",
    "\n",
    "#### 1) Calculate the average SRT of every 10 minutes, and plot the SRT with a line chart (x axis for date time and y axis for the average SRT).\n",
    "\n",
    "#### 2) Calculate the average of each SRT component of every 10 minute, and plot the four SRT components together with a stacked area chart (x axis for date time and y axis for time) and also a 100% stacked area chart (y axis for the percentage).\n",
    "\n",
    "#### 3) Plot the CDF (Cumulative distribution function) chart of SRT.\n",
    "\n",
    "#### 4) Plot the CDF chart of #Images.\n",
    "\n",
    "#### 5) Count the number of queries (also called page views or PVs) of each minute, and plot the minute-level PVs with a line chart (x axis for date time and y axis for the PVs).\n",
    "\n",
    "#### 6) Count the PVs of each province, and plot it with a histogram chart (x axis for province and y axis for PVs).\n",
    "\n",
    "#### 7) Count the PVs of each UA, and plot it with a pie chart (show the percentages in the chart).\n",
    "\n",
    "#### 8) What are the differences among those charts (How to decide which one to use)\n",
    "\n",
    "#### 9) Describe your experience or findings in doing those jobs. For example, experience of processing the data, observations from the charts, characteristics of the data, potential explanations, and any interesting things you would like to mention.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "####  [Dropbox](https://www.dropbox.com/s/akef557hnla0h9v/ANM-data.zip?dl=0) / [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/c8806b4c81ee45afa03c/?dl=1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Preliminary preparations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "\n",
    "import glob, os\n",
    "\n",
    "path = os.getcwd()\n",
    "csv_files = glob.glob(path+ \"/dataset/*.csv\")\n",
    "\n",
    "dataset = []\n",
    "for file in csv_files:\n",
    "    content = pd.read_csv(file, index_col=None, header=0)\n",
    "    dataset.append(content)\n",
    "dataset = pd.concat(dataset, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "source": [
    "import datetime as dt\n",
    "\n",
    "dataset['time'] = pd.to_datetime(dataset['Timestamp'])\n",
    "diffs = dataset['time'] - dataset['time'].shift()\n",
    "laps = diffs > pd.Timedelta('10 min')\n",
    "periods = laps.cumsum().apply(lambda x: 'period_{}'.format(x+1))\n",
    "dataset['10min_period'] = periods"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}